---
title: "Merged Nutnet Plots"
author: "Nathan Hwangbo"
date: "12/6/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


### Reading in Data
* Removed the site `comp.pt`
* filtered for `live ==1`
* computed relative cover as $\frac{\text{max cover}}{\text{totplotcover.yr.live} \times 100}$

_Note:_ The new data Laura sent us (as of 12/12/19) is missing all of the treatments for live == 1. The code will run using the original merged data provided to us (we have it named `merged_NutNet_Oct2019_old.csv`).
```{r data, warning=FALSE, message=FALSE, cache = T}
library(merTools)
library(doParallel)
library(here)
library(tidyverse)
library(lme4)
library(merTools)
library(patchwork)

registerDoParallel()

## Reading in data
nutnetdf_raw <-read.csv(here("output-data", "merged_NutNet_Oct2019_old.csv"), stringsAsFactors = FALSE, colClasses = c("site_code" = "factor")) %>%
  # for Doane College Spring Creek Prarie, there's an extra space
  # nh 2/2/20: join is messed up because of this. need to fix.
  mutate(site_name.y = str_trim(site_name.y))

# Getting rid of identical, duplicate columns
# removing problematic site code comp.pt
nutnetdf <- nutnetdf_raw %>%
  select(-c(block.y, site_name.y, trt.y,  year_trt.y)) %>%
  rename(block = "block.x", site_name = "site_name.x", trt= "trt.x", year_trt = "year_trt.x") %>%
  filter(site_code !="comp.pt")


# The plots will focus on live biomass, so this will be our base dataset.
nutnetRel <- nutnetdf %>%
  filter(live == 1) %>%
  mutate(rel_cover = (max_cover/totplotcover.yr.live )*100) 


# this will come in handy when we're actually plotting the data.
nutnetPlot <- nutnetRel %>%
  filter(trt %in% c("Control", "Fence", "N", "NP", "NPK", "Fence", "NPK+Fence"))
```

### Setup code borrowed from `nutnet_rare_spp.R`
```{r helpers}

# plot settings
theme_set(theme_bw())
theme_update(axis.title.x=element_text(size=20, vjust=-0.35, margin=margin(t=15)), axis.text.x=element_text(size=16),
             axis.title.y=element_text(size=20, angle=90, vjust=0.5, margin=margin(r=15)), axis.text.y=element_text(size=16),
             plot.title = element_text(size=24, vjust=2),
             panel.grid.major=element_blank(), panel.grid.minor=element_blank(),
             legend.title=element_blank(), legend.text=element_text(size=20))


### Helper Function: Compute a bunch of summary statistics for plotting
barGraphStats <- function(data, variable, byFactorNames) {
  count <- length(byFactorNames)
  N <- aggregate(data[[variable]], data[byFactorNames], FUN=length)
  names(N)[1:count] <- byFactorNames
  names(N) <- sub("^x$", "N", names(N))
  mean <- aggregate(data[[variable]], data[byFactorNames], FUN=mean)
  names(mean)[1:count] <- byFactorNames
  names(mean) <- sub("^x$", "mean", names(mean))
  sd <- aggregate(data[[variable]], data[byFactorNames], FUN=sd)
  names(sd)[1:count] <- byFactorNames
  names(sd) <- sub("^x$", "sd", names(sd))
  preSummaryStats <- merge(N, mean, by=byFactorNames)
  finalSummaryStats <- merge(preSummaryStats, sd, by=byFactorNames)
  finalSummaryStats$se <- finalSummaryStats$sd / sqrt(finalSummaryStats$N)
  return(finalSummaryStats)
}  


###count concecutive 0's: how long is a sp lost?
cumul_zeros <- function(x)  {
  x <- !x
  rl <- rle(x)
  len <- rl$lengths
  v <- rl$values
  cumLen <- cumsum(len)
  z <- x
  # replace the 0 at the end of each zero-block in z by the 
  # negative of the length of the preceding 1-block....
  iDrops <- c(0, diff(v)) < 0
  z[ cumLen[ iDrops ] ] <- -len[ c(iDrops[-1],FALSE) ]
  # ... to ensure that the cumsum below does the right thing.
  # We zap the cumsum with x so only the cumsums for the 1-blocks survive:
  x*cumsum(z)
}

```




### Aside: How to compute Richness?
Currently, we use the `Rich` column given to us by nutnet (In particular, the dataset `comb-by-plot-clim-soil-diversity-09-Apr-2018.csv`). However, in `NutNet_rare_spp.R`, richness is computed using the `full-biomass-09-June-2017.csv` data. In the code chunk below, we use the merged data (`merged_NutNet_Oct2019.csv`), compute richness using the original method outlined in `NutNet_rare_spp.R`, tweak this method by changing the `group_by`, and compare these two methods to the built in `rich` column.

* Neither method for computing richness aligns with `rich`.
    * Q: How is `rich` computed then?
* The rest of the analysis uses the column `rich`
```{r}
##### Kim's raw version (from NutNet_rare_spp.R). Nathan's only change is moving to the merged data.
richness_raw <- nutnetRel%>%
  filter(live==1, Family!='NULL')%>%
  group_by(year_trt, site_code, plot, trt)%>%
  summarise(richness_og =length(rel_cover))%>%
  ungroup()

#### Adapted (computed) version, counting unique taxon instead of rows, don't group by plot
richness_taxon <- nutnetRel%>%
  filter(live==1, Family!='NULL')%>%
  group_by(year_trt, site_code)%>%
  summarise(richness_adapt=length(unique(Taxon)))%>%
  ungroup()


#### Compare with the nutnet built in version. They still don't match
nutnetRel %>%
  select(year_trt, site_code, plot, trt, rich) %>%
  inner_join(richness_raw, by = c("year_trt", "site_code", "plot", "trt")) %>%
  inner_join(richness_taxon, by = c("year_trt", "site_code")) %>%
  filter(richness_og != rich | richness_adapt != rich | richness_og != richness_adapt)
  #filter(!isTRUE(all.equal(rich, richness_og, richness_adapt)))


```




### Plot 1 from `nutnet_rare_spp.R`: Biomass ~ Richness (log scale). 
* Using `rich` for richness
* Using `live_mass` for biomass
* Plotting linear and locally linear trendlines
* Including only the treatments :Control, N, NP, NPK, Fence, NPK+Fence
* We take the average richness/live mass over all Taxon
    * Equivalently, this means each point in our plot is a unique site / year / treatment / plot combination
    * Q: Is this what we want?
```{r slide4, cache = T}
# aggregate over taxon
biomass_by_trt <- nutnetPlot %>%
  filter(year_trt != 0) %>%
  group_by(site_code, year_trt, trt, plot) %>% 
  summarize(mean_rich = mean(rich),
            mean_mass = mean(live_mass))

# locally linear trendlines
(biotime_plot1_loess <- ggplot(biomass_by_trt, aes(x=log(mean_rich), y=log(mean_mass), color=trt)) + 
    #guides(color = "none") +
    geom_point(alpha = 0.01) +
    geom_smooth(method='loess', alpha=0.3, lwd=1.3, se=T) +
    #geom_smooth(pred_bef_fix, method='lm', mapping=aes(y=fit), color="black", lwd=1.5) +
    labs(x = "Log Richness",
         y = "Log Biomass",
         title = "Biomass vs Richness by Treatment",
         color = "Treatment") + 
    ylim(c(4,6.5))
)

# linear trendlines
(biotime_plot1_lm <- ggplot(biomass_by_trt, aes(x=log(mean_rich), y=log(mean_mass), color=trt)) + 
    #guides(color = "none") +
    geom_point(alpha = 0.01) +
    geom_smooth(method='lm', alpha=0.3, lwd=1.3, se=T) +
    #geom_smooth(pred_bef_fix, method='lm', mapping=aes(y=fit), color="black", lwd=1.5) +
    labs(x = "Log Richness",
         y = "Log Biomass",
         title = "Biomass vs Richness by Treatment (Linear Trendlines)") + 
    ylim(c(4,6.5))
)

```

### Plot2 from `nutnet_rare_spp.R`: Proportion of Species lost, by time

* Needs a lot of preprocessing work from Kim's script. This is confusing, and I'm pretty sure we can cut it down somehow. 
* _Note_: Need to check the computation of `nutnetdf_allspp`. I have a feeling we are `select`ing too many variables.. This will also impact the biotime plots. 
* Warning! This takes a pretty long time to run.
```{r slide5, cache = T}
nutnetpretreatdf <- nutnetRel %>%
  filter(year_trt == 0)

# get mean and max abundance for each Site/Year/Taxon.. ie aggregating over plot and treatment
meanmaxAb_byspecies <- nutnetpretreatdf %>%
  group_by(year, site_code, Taxon) %>%
  summarize(meanPTAbundance = mean(rel_cover, na.rm = T),
            maxPTAbundance = max(rel_cover)) %>%
  ungroup() %>%
  select(-year)

# Get the relative pretreatment frequency of each taxon, by year/site_code 
# ie (# of living things / number of plots)
# We first compute Total pretreatment Frequency by summing the live column (1)
# Then we get the number of plots for each site by taking max(plot) (2)
# Then we divide total frequency / number of plots (3)
tot_plots <- nutnetpretreatdf %>% #(2a)
  select(site_code, plot)%>%
  unique()%>%
  group_by(site_code)%>%
  summarise(num_plots=max(plot))

freq <- nutnetpretreatdf %>%
  group_by(year, site_code, Taxon) %>%
  summarize(PTfreq = sum(live, na.rm = T)) %>% # (1)
  ungroup() %>%
  select(-year) %>%
  left_join(tot_plots, by = "site_code") %>% #(2b)
  mutate(freq = PTfreq / num_plots) # (3)

freq2 <- nutnetpretreatdf %>%
  group_by(site_code, Taxon) %>%
  summarize(PTfreq = sum(live, na.rm = T)) %>% # (1)
  ungroup() %>%
  #select(-year) %>%
  left_join(tot_plots, by = "site_code") %>% #(2b)
  mutate(freq = PTfreq / num_plots) # (3)


# get the digroup to merge in with everything else later
di_groups <- nutnetRel %>%
  select(site_code, plot, Taxon, DIgroup) %>%
  distinct()


# Our data doesn't come with any rows where abundance is zero, 
# so we assume that unseen combinations of the data are zeroes:
# To be specific, for each site, we create every combination of (Plot, Year, Treatment) within that site (1)
# Then we take all the Taxon found in that site (at any point) and
# do a Cartesian product of (Plot, Year, Treatment) x Taxon. (2)
# Then we create a column called PA to represent the new rows we added. (3)
# Then we add back DI (since it had to be removed to do the groupings) (4)
nutnetdf_allspp <- nutnetRel %>%
  select(year, site_name, site_code, plot, year_trt, trt, Taxon, rel_cover) %>%
  group_by(site_name) %>%
  nest() %>% 
  mutate(spread_df = purrr::map(data, ~spread(., key = Taxon, value = rel_cover, fill = 0) %>% #(1)
                                  gather(key = Taxon, value = rel_cover, -year:-trt))) %>% #(2)
  unnest(spread_df) %>%
  ungroup() %>%
  mutate(PA = ifelse(rel_cover > 0, 1, 0)) %>% # (3)
  arrange(site_code, plot, Taxon, year) %>%
  left_join(di_groups, by = c("site_code", "plot", "Taxon")) #(4)



# get number of years observed. will be merged in with other stuff below
nutnetdf_length <- nutnetdf_allspp%>%
  #make a column for max trt year
  group_by(site_code)%>%
  summarise(length=max(year_trt))

#get the abundance metric to merge with everything else later (NH CHANGE)
# abund_metric_df <- nutnetdf_allspp3Trt %>%
#   select(site_code, Taxon, meanPTAbundance, abund_metric) %>%
#   distinct()

# Abundance metric = average of mean pretreatment abundance and pretreatment frequency?
nutnetPresAbs <- nutnetdf_allspp%>%
  left_join(meanmaxAb_byspecies, by=c('site_code', 'Taxon'))%>%
  left_join(freq, by=c('site_code', 'Taxon'))%>%
  mutate(abund_metric=((meanPTAbundance/100)+PTfreq)/2)%>%
  filter(year_trt>0)

nutnetPASite <- nutnetPresAbs%>%
  #get site level presence/absence by trt
  group_by(site_code, Taxon, year_trt, trt)%>%
  summarise(presence=sum(PA))%>%
  ungroup()%>%
  mutate(PA=ifelse(presence>0, 1, 0))

# Look at controls
nutnetPACtl <- nutnetPASite%>%
  filter(trt=='Control')%>%
  rename(PA_ctl=PA)%>%
  select(site_code, Taxon, year_trt, PA_ctl)

# look at treatment group and compare with controls
nutnetPASiteTrt <- nutnetPASite%>%
  filter(trt!='Control')%>%
  left_join(nutnetPACtl)%>%
  #drop species that are never present in control in a year (because those are gains in trts)
  filter(PA_ctl>0)%>%
  #merge dominance categories NH CHANGE from in-script di computation.
  # note that we're missing abund metric now, so have to add it separate
  left_join(di_groups, by = c("site_code", "Taxon"))# %>%
  #left_join(abund_metric_df, by = c("site_code", "Taxon"))

nutnetLossSite <- nutnetPASiteTrt%>%
  filter(PA==0)%>%
  group_by(site_code, year_trt, trt, DIgroup)%>%
  summarise(num_loss=length(PA))%>%
  ungroup()

# Looking at number of rows where species is present
nutnetNotLossSite <- nutnetPASiteTrt%>%
  filter(PA==1)%>%
  group_by(site_code, year_trt, trt, DIgroup)%>%
  summarise(num_notloss=length(PA))%>%
  ungroup()

# Getting the proportion of species lost in each row ?
nutnetLossorNotSite <- nutnetLossSite%>%
  full_join(nutnetNotLossSite)%>%
  mutate(num_loss=replace_na(num_loss, 0))%>%
  mutate(num_notloss=replace_na(num_notloss, 0))%>%
  mutate(total_spp=num_loss+num_notloss)%>%
  mutate(prop_loss=num_loss/total_spp)%>%
  #remove sites with no DI groups (no pretrt data)
  filter(!is.na(DIgroup))%>%
  #remove sites where trt year is not recorded
  filter(year_trt<11)


ggplot(barGraphStats(data=subset(nutnetLossorNotSite, 
                                 trt=='N'|trt=='NP'|trt=='NPK' | trt =="Fence" | trt == "NPK+Fence"), 
                     variable="prop_loss", 
                     byFactorNames=c("trt", "DIgroup", "year_trt")), 
       aes(x=year_trt, y=mean, color=as.factor(DIgroup))) +
  geom_point(stat='identity', position=position_dodge(width=0.7)) +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se), width=0.2, position=position_dodge(width=0.7)) +
  xlab('Year') + ylab('Proportion of Species Lost') +
  #scale_color_discrete(breaks=c("1", "2", "3"), labels=c("Rare", "Intermediate", "Dominant")) +
  facet_wrap(~trt) + 
  labs(color ="DI Group")


```


### Plot 3 from `nutnet_rare_spp.R`: Biomass/abudance difference over time
* Maybe include `plot` in the first group_by?
```{r slide6}
biomassResp <- nutnetRel %>%
  filter(year_trt!=0)%>%
  group_by(site_code, year_trt, trt)%>%
  summarise(live_mass_mean=mean(live_mass))%>%
  ungroup()%>%
  spread(key=trt, value=live_mass_mean)%>%
  mutate(NPK_diff=(NPK-Control)/Control, 
         N_diff=(N-Control)/Control, 
         NP_diff=(NP-Control)/Control,
         #NP_diff=(NP+Fence-Control)/Control,
         Fence_diff = (Fence - Control)/Control,
         NPKFence_diff = (`NPK+Fence` - Control)/Control)%>%
  select(site_code, year_trt, NPK_diff, N_diff, NP_diff, Fence_diff, NPKFence_diff)%>%
  na.omit()%>%
  gather(key=trt, value=diff, NPK_diff:NPKFence_diff)

(badBiomassFig <- ggplot(data=barGraphStats(data=biomassResp, variable="diff", byFactorNames=c("year_trt", "trt")), aes(x=year_trt, y=mean, color=trt)) +
    geom_point(size=3) +
    stat_smooth(method = "lm", formula = y ~ x + I(x^2), alpha = 0.2) +
    geom_errorbar(aes(ymin=mean-se, ymax=mean+se), width=0.2, alpha = 0.5) +
    xlab('Treatment Year') + ylab('Biomass Difference (%)') +
    geom_hline(yintercept=0) + 
    scale_color_discrete(name = "Treatment", labels = c("Fence", "N", "NP", "NPK", "NPK+Fence"))
  
)



```



### Plot b from Predict: Richness Difference (%) by DIGroup
* The boxplots are over all sites, and we're averaging over all years != 0
* Need to check computation of these. Based on the plot above to compute difference 
```{r slide7}
## What's are the points in the boxplot??  plot year
richness_diff_di <- nutnetRel %>%
  filter(year_trt!=0)%>%
  group_by(trt, site_code, DIgroup)%>%
  summarise(live_rich_mean=mean(rich))%>%
  ungroup()%>%
  spread(key=trt, value=live_rich_mean)%>%
  mutate(NPK_diff=(NPK-Control)/Control*100, 
         N_diff=(N-Control)/Control*100, 
         NP_diff=(NP-Control)/Control*100,
         #NP_diff=(NP+Fence-Control)/Control,
         Fence_diff = (Fence - Control)/Control*100,
         NPKFence_diff = (`NPK+Fence` - Control)/Control*100)%>%
  select(DIgroup, NPK = NPK_diff, N = N_diff, NP = NP_diff, Fence = Fence_diff, `NPK+Fence` = NPKFence_diff)%>%
  na.omit()%>%
  gather(key=trt, value=diff, NPK:`NPK+Fence`)


ggplot(richness_diff_di) + 
  geom_boxplot(aes(x = trt, y = diff, fill = DIgroup)) + 
  geom_hline(yintercept = 0) + 
  lims(y = c(-1,2)) + 
  labs(title = "Richness by Treatment, over all Sites",
       y = "Richness Difference (%)",
       x = "Treatment")

```


### Plot c from Predict. Abundance Diff (%) by DI Group
```{r slide8}
abund_diff_di <- nutnetRel %>%
  filter(year_trt!=0)%>%
  group_by(trt, site_code, DIgroup)%>%
  summarise(live_abund_mean=mean(DI))%>%
  ungroup()%>%
  spread(key=trt, value=live_abund_mean)%>%
  mutate(NPK_diff=(NPK-Control)/Control, 
         N_diff=(N-Control)/Control, 
         NP_diff=(NP-Control)/Control,
         #NP_diff=(NP+Fence-Control)/Control,
         Fence_diff = (Fence - Control)/Control,
         NPKFence_diff = (`NPK+Fence` - Control)/Control)%>%
  select(DIgroup, NPK = NPK_diff, N = N_diff, NP = NP_diff, Fence = Fence_diff, `NPK+Fence` = NPKFence_diff)%>%
  na.omit()%>%
  gather(key=trt, value=diff, NPK:`NPK+Fence`)

ggplot(abund_diff_di) + 
  geom_boxplot(aes(x = trt, y = diff, fill = DIgroup)) + 
  geom_hline(yintercept = 0) + 
  lims(y = c(-1,2)) + 
  labs(title = "Abundance by Treatment, over all Sites",
       y = "Abundance Difference (%)",
       x = "Treatment")



```



### Plot b from Biotime: Probability missing at the end ~ Relative Pretreatment Rank
* adapted from `2_biotime_sp_loss.R`
    * It looks like Kim uses some of this code in when she creates the dataframe `nutnetdf_allspp` (created above in chunk `slide5` above). I used Kim's adadptation as a starting point, but see my comments above `slide5` for some of my concerns about this.
    * I'm also not sure about groupings. I took Biotime's `STUDY_ID` identifier to be the combination of `site_code` and `plot` in our data. 


```{r, cache = T}
rel_rank_year0 <- nutnetRel %>%
  filter(year_trt == 0) %>%
  select(site_code, plot, trt, Taxon, rel_abundance_year0) %>%
  group_by(site_code, trt) %>%
  mutate(rel_rank_year0 = rank(rel_abundance_year0, ties.method = "min") %>%
           scales::rescale(c(0,1))) %>% 
  ungroup()
  

# site_code, plot, year, taxon is a unique identifier in our original data (nutnetRel)
modeling_data_year0 <- nutnetdf_allspp %>% 
  select(site_code, plot, year_trt, Taxon, rel_cover) %>%
  left_join(rel_rank_year0, by = c("site_code", "plot", "Taxon")) %>%
  # figure out when a species is lost
  group_by(site_code, plot, Taxon) %>%
  filter(year_trt == max(year_trt)) %>%
  ungroup() %>%
  mutate(lost_at_end = ifelse(rel_cover == 0, 1, 0)) %>%
  #mutate(lost_at_end = ifelse(rel_cover[1] == 0 & lead(rel_cover) == 0, 1, 0)) %>%
  filter(trt %in% c("Control", "N", "NP", "NPK", "NPK+Fence"))

# ggplot(aes(x = rel_rank_year0, y = lost_at_end, color = trt), data = modeling_data_year0) + 
#   geom_point(position=position_jitter(width=0.05, height=0.05),
#              alpha=0.2, color="grey") +
#     geom_smooth(method = "glm", method.args = list(family = "binomial")) + 
#   ylab("Probability of Being\n Missing at End") +
#   xlab("Relative Rank at 1st Time Step\n(Rare to Common)")




         

year0_model <- glmer(lost_at_end ~ rel_rank_year0  + (1|site_code/plot) + (1|Taxon),
                   data = modeling_data_year0,
                   family = "binomial")
year0_data_with_fitted_values <- modelr::add_predictions(data = modeling_data_year0, 
                                                 model = year0_model, 
                                                 type = "response")

ggplot(aes(x = rel_rank_year0, y = pred, color = trt), data = year0_data_with_fitted_values) + 
  # geom_point(aes(x = rel_rank_year0, y = lost_at_end), position=position_jitter(width=0.05, height=0.05),
  #            alpha=0.2, color="grey") +
  geom_smooth() +
  labs(
    y = "Probability of Being\n Missing at End",
    x = "Relative Rank at 1st Time Step\n(Rare to Common)",
    color = "Treatment")

ggsave("biotime_b_equiv.png")

# newdata <- crossing(site_code = modeling_data_year0$site_code %>% unique,
#                     plot = unique(modeling_data_year0$plot),
#                     rel_rank_year0 = seq(0,1,length.out = 100),
#                     Taxon = modeling_data_year0$Taxon %>% unique)
# 
# fake_pred <- predictInterval(year0_model, newdata = newdata)
# 
# fake_data <- cbind(newdata, fake_pred)
# 
# 
# (plot_year0 <- ggplot(fake_data, 
#                              aes(x = rel_rank_year0, y = lost_at_end, color = trt)) +
#     #geom_smooth(method = "glm", method.args = list(family = "binomial")) +  
#     
#   geom_line(mapping = aes(color = factor(DIgroup)),
#                           # color = factor(lag_rel_percapita_biomass_rank)),
#             size = 2) +
#   scale_color_viridis_d(guide = guide_legend(title = "Relative\nSize Rank\nAt Time T-1"),
#                         option = "D") +
#   scale_fill_viridis_d(guide = guide_legend(title = "Relative\nSize Rank\nAt Time T-1"),
#                        option = "D") +
#   # geom_ribbon(data = loss_lag_pred_fix,
#   #             mapping = aes(x = lag_rel_abund_rank,  group = lagsize_split,
#   #                           fill = factor(lag_rel_percapita_biomass_rank),
#   #                           ymin = lwr, ymax = upr), alpha = 0.3) +
#   xlab("Relative Abundance Rank At Time T-1") +
#   ylab("Probability of Loss at Time T")
# )

```




### Plot c from biotime.
* adapted from `5_biotime_abund_biomass_loss.R`
  * The biotime code looks like it actually has time t = 0 on the x axis... not a shifting t-1
* see concerns from plot b in the chunk above.
   * the `group_by`'s are my biggest concern.
* The problem is that the `rel_cover` == 0 rows are artifically created in `nutnetdf_allspp` (with the spread/gather shenanigans), and every new row also corresponds to a new treatment year. This means that we're inducing a TON of zeroes, so that the rankings (which treat all the 0's as a tie for 0), create this huge gap in the ranking between 0 and the next value. To "fix" this issue, I excluded the 0's, ranked the remaining observations, and threw the 0's back in there.

Rank by site, treatment, and year
```{r, cache = T}
### Compute the relative cover rankings within each site code and year
#     To stop the ton of induced zeroes from impacting the rankings, we 
#         (1) Turn the zeroes into NAs
#         (2) Use the "na.last" argument in `rank` to exclude NAs from ranking
#         (3) Rank the observations within each site and year, and change the ranking scale to be in (0,1)
#         (4) Change the NA ranks back to zeroes.
#         (5) Shift the ranks back so that they refer to the year before (for each taxon within a site/plot)

rel_rank_by_year <- nutnetdf_allspp %>%
  select(site_code, plot, year_trt, Taxon, rel_cover, trt) %>%
  # # we want to make the ranking based on mean realtive cover for taxon in a given plot and year.
  # group_by(site_code, plot, Taxon, year_trt) %>%
  # mutate(rel_abundance = mean(rel_cover)) %>%
  # ungroup() %>%
  # we want to rank the taxon among all the plots in a given site for a given treatment
  group_by(site_code, trt, year_trt) %>%
  # mutate(rel_rank = rank(rel_abundance, ties.method = "min")) %>%
  # mutate(rel_rank = ifelse(rel_cover == 0, 0, rel_rank)) %>%
  # mutate(rel_rank = rel_rank)
  mutate(rel_cover_explicit_na = ifelse(rel_cover == 0, NA, rel_cover), #(1)
         rel_rank_scaled = rank(rel_cover_explicit_na, ties.method = "min", na.last = "keep") %>% #(2)
           scales::rescale(c(0,1)),  #(3)
         rel_rank_implicit_na = ifelse(is.na(rel_rank_scaled), 0, rel_rank_scaled)) %>%#(4)
  ungroup() %>%
  # we want the lag to be by site and taxon. I think we also need to include plot because otherwise the lag will carry other into other plots, which could have different years.
  group_by(site_code, Taxon, plot) %>%
  # sort the rows
  arrange(site_code, plot, Taxon, year_trt) %>%
  # only works because we sort by year
  mutate(rel_rank_lag = lag(rel_rank_implicit_na)) %>%  #(5)
  select(-rel_cover) %>%
  ungroup()


treatments <- nutnetRel %>%
  select(trt, site_code, plot, Taxon)

# site_code, plot, year, taxon is a unique identifier in our data
modeling_data <- nutnetdf_allspp %>%
  filter(trt %in% c("Control", "N", "NP", "NPK", "NPK+Fence")) %>%
  left_join(rel_rank_by_year, by = c("site_code", "plot", "Taxon", "year_trt")) %>%
  select(site_code, plot, year_trt, Taxon, rel_cover, rel_rank_lag, rel_rank_scaled) %>%
  # the join creates NAs in lag_rel_rank at all the new "year_trts" from the new rows
  left_join(treatments, by = c("site_code", "plot", "Taxon")) %>%
  # figure out when a species is lost
  #group_by(site_code, plot, Taxon, year_trt) %>%
  #mutate(lost = ifelse(rel_cover ==0 & rel_rank_lag != 0, 1, 0)) %>%
  mutate(lost = ifelse(rel_cover == 0, 1, 0)) %>%
  #ungroup() %>%
  filter(
         # Because of how lag works, this is getting rid of all the first treatment years. 
         # the model already ignores these NAs. This just makes it explicit.
         !is.na(rel_rank_lag)) 

# # plot using a single variable glm.
# ggplot(aes(x = rel_rank_lag, y = lost, color = trt), data = modeling_data) + 
#   # geom_point(position=position_jitter(width=0.05, height=0.05),
#   #            alpha=0.2, color="grey") +
#     geom_smooth(method = "glm", method.args = list(family = "binomial")) + 
#   labs(x = "Relative Abundance Rank at Time T-1",
#        y = "Probability of Loss at Time T",
#        color = "Treatment")

# try a mixed effects model
multiyear_model <- glmer(lost ~ rel_rank_lag  + (1|site_code/plot) + (1|Taxon),
                   data = modeling_data,
                   family = "binomial")

summary(multiyear_model)
car::Anova(multiyear_model)
#piecewiseSEM::rsquared(multiyear_model)


# add a column in the dataframe for predictions
multiyear_data_with_fitted_values <- modelr::add_predictions(data = modeling_data, 
                                                 model = multiyear_model, 
                                                 type = "response")

# plot the mixed effects model.
(site_trt_yr <- ggplot(aes(x = rel_rank_lag, y = pred, color = trt), 
                      data = multiyear_data_with_fitted_values) + 
  geom_smooth() +
  labs(title = "Ranked by Site, Trt, Year",
       x = "Relative Abundance Rank at Time T-1",
       y = "Probability of Loss at Time T",
       color = "Treatment") + 
    theme(axis.title.x = element_text(size = 15),
          axis.title.y = element_text(size = 15),
          plot.title = element_text(size = 15))
)
#ggsave("biotime_c_equiv.png")


(rank_dist_site_trt_yr <- modeling_data %>%
  #filter(rel_rank_scaled != 0) %>%
  ggplot() + 
  geom_histogram(aes(rel_rank_scaled, color = year_trt), position = "stack") + 
  facet_wrap(~trt) + 
    labs(title = "site, year, trt")
)
```


Rank by site, treatment, plot, and year
```{r, cache = T}
### Compute the relative cover rankings within each site code and year
#     To stop the ton of induced zeroes from impacting the rankings, we 
#         (1) Turn the zeroes into NAs
#         (2) Use the "na.last" argument in `rank` to exclude NAs from ranking
#         (3) Rank the observations within each site and year, and change the ranking scale to be in (0,1)
#         (4) Change the NA ranks back to zeroes.
#         (5) Shift the ranks back so that they refer to the year before (for each taxon within a site/plot)

rel_rank_by_year_plot_trt <- nutnetdf_allspp %>%
  select(site_code, plot, year_trt, Taxon, rel_cover, trt) %>%
  # # we want to make the ranking based on mean realtive cover for taxon in a given plot and year.
  # group_by(site_code, plot, Taxon, year_trt) %>%
  # mutate(rel_abundance = mean(rel_cover)) %>%
  # ungroup() %>%
  # we want to rank the taxon among all the plots in a given site for a given treatment
  group_by(site_code, trt, plot, year_trt) %>%
  # mutate(rel_rank = rank(rel_abundance, ties.method = "min")) %>%
  # mutate(rel_rank = ifelse(rel_cover == 0, 0, rel_rank)) %>%
  # mutate(rel_rank = rel_rank)
  mutate(rel_cover_explicit_na = ifelse(rel_cover == 0, NA, rel_cover), #(1)
         rel_rank_scaled = rank(rel_cover_explicit_na, ties.method = "min", na.last = "keep") %>% #(2)
           scales::rescale(c(0,1)),  #(3)
         rel_rank_implicit_na = ifelse(is.na(rel_rank_scaled), 0, rel_rank_scaled)) %>%#(4)
  ungroup() %>%
  # we want the lag to be by site and taxon. I think we also need to include plot because otherwise the lag will carry other into other plots, which could have different years.
  group_by(site_code, Taxon, plot) %>%
  # sort the rows
  arrange(site_code, plot, Taxon, year_trt) %>%
  # only works because we sort by year
  mutate(rel_rank_lag = lag(rel_rank_implicit_na)) %>%  #(5)
  select(-rel_cover) %>%
  ungroup()


treatments <- nutnetRel %>%
  select(trt, site_code, plot, Taxon)

# site_code, plot, year, taxon is a unique identifier in our data
modeling_data_plot_trt <- nutnetdf_allspp %>% 
  filter(trt %in% c("Control", "N", "NP", "NPK", "NPK+Fence")) %>%
  left_join(rel_rank_by_year_plot_trt, by = c("site_code", "plot", "Taxon", "year_trt")) %>%
  select(site_code, plot, year_trt, Taxon, rel_cover, rel_rank_lag, rel_rank_scaled) %>%
  # the join creates NAs in lag_rel_rank at all the new "year_trts" from the new rows
  left_join(treatments, by = c("site_code", "plot", "Taxon")) %>%
  # figure out when a species is lost
  #group_by(site_code, plot, Taxon, year_trt) %>%
  #mutate(lost = ifelse(rel_cover ==0 & rel_rank_lag != 0, 1, 0)) %>%
  mutate(lost = ifelse(rel_cover == 0, 1, 0)) %>%
  #ungroup() %>%
  filter(
         # Because of how lag works, this is getting rid of all the first treatment years. 
         # the model already ignores these NAs. This just makes it explicit.
         !is.na(rel_rank_lag)) 

# # plot using a single variable glm.
# ggplot(aes(x = rel_rank_lag, y = lost, color = trt), data = modeling_data) + 
#   # geom_point(position=position_jitter(width=0.05, height=0.05),
#   #            alpha=0.2, color="grey") +
#     geom_smooth(method = "glm", method.args = list(family = "binomial")) + 
#   labs(x = "Relative Abundance Rank at Time T-1",
#        y = "Probability of Loss at Time T",
#        color = "Treatment")

# try a mixed effects model
multiyear_model_plot_trt <- glmer(lost ~ rel_rank_lag  + (1|site_code/plot) + (1|Taxon),
                   data = modeling_data_plot,
                   family = "binomial")

summary(multiyear_model_plot)
car::Anova(multiyear_model_plot)
#piecewiseSEM::rsquared(multiyear_model_plot)


# add a column in the dataframe for predictions
multiyear_data_with_fitted_values_plot_trt <- modelr::add_predictions(data = modeling_data_plot_trt, 
                                                 model = multiyear_model_plot_trt, 
                                                 type = "response")

# plot the mixed effects model.
(site_trt_plot_year <- ggplot(aes(x = rel_rank_lag, y = pred, color = trt), 
                              data = multiyear_data_with_fitted_values_plot) + 
  geom_smooth() +
  labs(title = "Ranked by Site, Plot, Trt, Year",
       x = "Relative Abundance Rank at Time T-1",
       y = "Probability of Loss at Time T",
       color = "Treatment")+ 
    theme(axis.title.x = element_text(size = 15),
          axis.title.y = element_text(size = 15),
          plot.title = element_text(size = 15))
)

#ggsave("biotime_c_equiv.png")


(rank_dist_site_trt_yr_plot <- modeling_data_plot_trt %>%
  #filter(rel_rank_scaled != 0) %>%
  ggplot() + 
  geom_histogram(aes(rel_rank_scaled, color = year_trt), position = "stack") + 
  facet_wrap(~trt) +
  labs(title ="site, year, plot, trt")
)
```


Just by site and year.
```{r, cache = T}
### Compute the relative cover rankings within each site code and year
#     To stop the ton of induced zeroes from impacting the rankings, we 
#         (1) Turn the zeroes into NAs
#         (2) Use the "na.last" argument in `rank` to exclude NAs from ranking
#         (3) Rank the observations within each site and year, and change the ranking scale to be in (0,1)
#         (4) Change the NA ranks back to zeroes.
#         (5) Shift the ranks back so that they refer to the year before (for each taxon within a site/plot)

rel_rank_by_year_siteyear <- nutnetdf_allspp %>%
  select(site_code, plot, year_trt, Taxon, rel_cover, trt) %>%
  filter(trt %in% c("Control", "N", "NP", "NPK", "NPK+Fence")) %>%
  # # we want to make the ranking based on mean realtive cover for taxon in a given plot and year.
  # group_by(site_code, plot, Taxon, year_trt) %>%
  # mutate(rel_abundance = mean(rel_cover)) %>%
  # ungroup() %>%
  # we want to rank the taxon among all the plots in a given site for a given treatment
  group_by(site_code, year_trt) %>%
  # mutate(rel_rank = rank(rel_abundance, ties.method = "min")) %>%
  # mutate(rel_rank = ifelse(rel_cover == 0, 0, rel_rank)) %>%
  # mutate(rel_rank = rel_rank)
  mutate(rel_cover_explicit_na = ifelse(rel_cover == 0, NA, rel_cover), #(1)
         rel_rank_scaled = rank(rel_cover_explicit_na, ties.method = "min", na.last = "keep") %>% #(2)
           scales::rescale(c(0,1)),  #(3)
         rel_rank_implicit_na = ifelse(is.na(rel_rank_scaled), 0, rel_rank_scaled)) %>%#(4)
  ungroup() %>%
  # we want the lag to be by site and taxon. I think we also need to include plot because otherwise the lag will carry other into other plots, which could have different years.
  group_by(site_code, Taxon, plot) %>%
  # sort the rows
  arrange(site_code, plot, Taxon, year_trt) %>%
  # only works because we sort by year
  mutate(rel_rank_lag = lag(rel_rank_implicit_na)) %>%  #(5)
  select(-rel_cover) %>%
  ungroup()


treatments <- nutnetRel %>%
  select(trt, site_code, plot, Taxon)

# site_code, plot, year, taxon is a unique identifier in our data
modeling_data_siteyear <- nutnetdf_allspp %>% 
  left_join(rel_rank_by_year_siteyear, by = c("site_code", "plot", "Taxon", "year_trt")) %>%
  select(site_code, plot, year_trt, Taxon, rel_cover, rel_rank_lag, rel_rank_scaled) %>%
  # the join creates NAs in lag_rel_rank at all the new "year_trts" from the new rows
  left_join(treatments, by = c("site_code", "plot", "Taxon")) %>%
  # figure out when a species is lost
  #group_by(site_code, plot, Taxon, year_trt) %>%
  #mutate(lost = ifelse(rel_cover ==0 & rel_rank_lag != 0, 1, 0)) %>%
  mutate(lost = ifelse(rel_cover == 0, 1, 0)) %>%
  #ungroup() %>%
  filter(
         # Because of how lag works, this is getting rid of all the first treatment years. 
         # the model already ignores these NAs. This just makes it explicit.
         !is.na(rel_rank_lag)) 


# # plot using a single variable glm.
# ggplot(aes(x = rel_rank_lag, y = lost, color = trt), data = modeling_data) + 
#   # geom_point(position=position_jitter(width=0.05, height=0.05),
#   #            alpha=0.2, color="grey") +
#     geom_smooth(method = "glm", method.args = list(family = "binomial")) + 
#   labs(x = "Relative Abundance Rank at Time T-1",
#        y = "Probability of Loss at Time T",
#        color = "Treatment")

# try a mixed effects model
multiyear_model_siteyear <- glmer(lost ~ rel_rank_lag  + (1|site_code/plot) + (1|Taxon),
                   data = modeling_data_siteyear,
                   family = "binomial")


summary(multiyear_model)
car::Anova(multiyear_model)
#piecewiseSEM::rsquared(multiyear_model)


# add a column in the dataframe for predictions
multiyear_data_with_fitted_values_siteyear <- modelr::add_predictions(data = modeling_data_siteyear, 
                                                 model = multiyear_model_siteyear, 
                                                 type = "response")

# plot the mixed effects model.
(site_year <- ggplot(aes(x = rel_rank_lag, y = pred, color = trt), 
                     data = multiyear_data_with_fitted_values_siteyear) + 
  geom_smooth() +
  labs(title = "Ranked by Site, Year",
       x = "Relative Abundance Rank at Time T-1",
       y = "Probability of Loss at Time T",
       color = "Treatment") + 
    theme(axis.title.x = element_text(size = 15),
          axis.title.y = element_text(size = 15),
          plot.title = element_text(size = 15))
)
#ggsave("biotime_c_equiv.png")



site_year + site_trt_yr + site_trt_plot_year + 
  plot_layout(guides = "collect") + 
  plot_annotation(title = "Comparison of ranking methods")

ggsave(filename = "ranking_comparison.png", units = "in", width = 15, height = 5)
```

```{r}
(rank_dist_site_yr <- modeling_data_siteyear %>%
  #filter(rel_rank_scaled != 0) %>%
  ggplot() + geom_histogram(aes(rel_rank_scaled, color = year_trt), position = "stack") + facet_wrap(~trt) + 
   labs(title ="site, year")
)


rel_rank_by_year_plot <- nutnetdf_allspp %>%
  select(site_code, plot, year_trt, Taxon, rel_cover, trt) %>%
  # # we want to make the ranking based on mean realtive cover for taxon in a given plot and year.
  # group_by(site_code, plot, Taxon, year_trt) %>%
  # mutate(rel_abundance = mean(rel_cover)) %>%
  # ungroup() %>%
  # we want to rank the taxon among all the plots in a given site for a given treatment
  group_by(site_code, plot, year_trt) %>%
  # mutate(rel_rank = rank(rel_abundance, ties.method = "min")) %>%
  # mutate(rel_rank = ifelse(rel_cover == 0, 0, rel_rank)) %>%
  # mutate(rel_rank = rel_rank)
  mutate(rel_cover_explicit_na = ifelse(rel_cover == 0, NA, rel_cover), #(1)
         rel_rank_scaled = rank(rel_cover_explicit_na, ties.method = "min", na.last = "keep") %>% #(2)
           scales::rescale(c(0,1)),  #(3)
         rel_rank_implicit_na = ifelse(is.na(rel_rank_scaled), 0, rel_rank_scaled)) %>%#(4)
  ungroup() %>%
  # we want the lag to be by site and taxon. I think we also need to include plot because otherwise the lag will carry other into other plots, which could have different years.
  group_by(site_code, Taxon, plot) %>%
  # sort the rows
  arrange(site_code, plot, Taxon, year_trt) %>%
  # only works because we sort by year
  mutate(rel_rank_lag = lag(rel_rank_implicit_na)) %>%  #(5)
  select(-rel_cover) %>%
  ungroup()


# site_code, plot, year, taxon is a unique identifier in our data
modeling_data_year_plot <- nutnetdf_allspp %>% 
  filter(trt %in% c("Control", "N", "NP", "NPK", "NPK+Fence")) %>%
  left_join(rel_rank_by_year_plot, by = c("site_code", "plot", "Taxon", "year_trt")) %>%
  select(site_code, plot, year_trt, Taxon, rel_cover, rel_rank_lag, rel_rank_scaled) %>%
  # the join creates NAs in lag_rel_rank at all the new "year_trts" from the new rows
  left_join(treatments, by = c("site_code", "plot", "Taxon")) %>%
  # figure out when a species is lost
  #group_by(site_code, plot, Taxon, year_trt) %>%
  #mutate(lost = ifelse(rel_cover ==0 & rel_rank_lag != 0, 1, 0)) %>%
  mutate(lost = ifelse(rel_cover == 0, 1, 0)) %>%
  #ungroup() %>%
  filter(
         # Because of how lag works, this is getting rid of all the first treatment years. 
         # the model already ignores these NAs. This just makes it explicit.
         !is.na(rel_rank_lag)) 

(rank_dist_plot_yr <- modeling_data_year_plot %>%
  #filter(rel_rank_scaled != 0) %>%
  ggplot() + geom_histogram(aes(rel_rank_scaled, color = year_trt), position = "stack") + facet_wrap(~trt) + 
   labs(title ="site, year, plot")
)


rank_dist_site_yr + rank_dist_site_trt_yr + rank_dist_site_trt_yr_plot + rank_dist_plot_yr
```


