---
title: "Merged Nutnet Plots"
author: "Nathan Hwangbo"
date: "12/6/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


### Reading in Data
* Removed the site `comp.pt`
* filtered for `live ==1`
* computed relative cover as $\frac{\text{max cover}}{\text{totplotcover.yr.live} \times 100}$

_Note:_ The new data Laura sent us (as of 12/12/19) is missing all of the treatments. The code will run using the original merged data provided to us (we have it named `merged_NutNet_Oct2019_old.csv`).
```{r data, warning=FALSE, message=FALSE, cache = T}
library(merTools)
library(doParallel)
library(here)
library(tidyverse)

registerDoParallel()


## Reading in data
nutnetdf_raw <-read.csv(here("output-data", "merged_NutNet_Oct2019_old.csv"), stringsAsFactors = FALSE, colClasses = c("site_code" = "factor")) %>%
  # for Doane College Spring Creek Prarie, there's an extra space
  mutate(site_name.y = str_trim(site_name.y))

# Getting rid of identical, duplicate columns
# removing problematic site code comp.pt
nutnetdf <- nutnetdf_raw %>%
  select(-c(block.y, site_name.y, trt.y,  year_trt.y)) %>%
  rename(block = "block.x", site_name = "site_name.x", trt= "trt.x", year_trt = "year_trt.x") %>%
  filter(site_code !="comp.pt")


# The plots will focus on live biomass, so this will be our base dataset.
nutnetRel <- nutnetdf %>%
  filter(live == 1) %>%
  mutate(rel_cover = (max_cover/totplotcover.yr.live )*100) 


# this will come in handy when we're actually plotting the data.
nutnetPlot <- nutnetRel %>%
  filter(trt %in% c("Control", "Fence", "N", "NP", "NPK", "Fence", "NPK+Fence"))
```

### Setup code borrowed from `nutnet_rare_spp.R`
```{r helpers}

# plot settings
theme_set(theme_bw())
theme_update(axis.title.x=element_text(size=20, vjust=-0.35, margin=margin(t=15)), axis.text.x=element_text(size=16),
             axis.title.y=element_text(size=20, angle=90, vjust=0.5, margin=margin(r=15)), axis.text.y=element_text(size=16),
             plot.title = element_text(size=24, vjust=2),
             panel.grid.major=element_blank(), panel.grid.minor=element_blank(),
             legend.title=element_blank(), legend.text=element_text(size=20))


### Helper Function: Compute a bunch of summary statistics for plotting
barGraphStats <- function(data, variable, byFactorNames) {
  count <- length(byFactorNames)
  N <- aggregate(data[[variable]], data[byFactorNames], FUN=length)
  names(N)[1:count] <- byFactorNames
  names(N) <- sub("^x$", "N", names(N))
  mean <- aggregate(data[[variable]], data[byFactorNames], FUN=mean)
  names(mean)[1:count] <- byFactorNames
  names(mean) <- sub("^x$", "mean", names(mean))
  sd <- aggregate(data[[variable]], data[byFactorNames], FUN=sd)
  names(sd)[1:count] <- byFactorNames
  names(sd) <- sub("^x$", "sd", names(sd))
  preSummaryStats <- merge(N, mean, by=byFactorNames)
  finalSummaryStats <- merge(preSummaryStats, sd, by=byFactorNames)
  finalSummaryStats$se <- finalSummaryStats$sd / sqrt(finalSummaryStats$N)
  return(finalSummaryStats)
}  


###count concecutive 0's: how long is a sp lost?
cumul_zeros <- function(x)  {
  x <- !x
  rl <- rle(x)
  len <- rl$lengths
  v <- rl$values
  cumLen <- cumsum(len)
  z <- x
  # replace the 0 at the end of each zero-block in z by the 
  # negative of the length of the preceding 1-block....
  iDrops <- c(0, diff(v)) < 0
  z[ cumLen[ iDrops ] ] <- -len[ c(iDrops[-1],FALSE) ]
  # ... to ensure that the cumsum below does the right thing.
  # We zap the cumsum with x so only the cumsums for the 1-blocks survive:
  x*cumsum(z)
}

```




### Aside: How to compute Richness?
Currently, we use the `Rich` column given to us by nutnet (In particular, the dataset `comb-by-plot-clim-soil-diversity-09-Apr-2018.csv`). However, in `NutNet_rare_spp.R`, richness is computed using the `full-biomass-09-June-2017.csv` data. In the code chunk below, we use the merged data (`merged_NutNet_Oct2019.csv`), compute richness using the original method outlined in `NutNet_rare_spp.R`, tweak this method by changing the `group_by`, and compare these two methods to the built in `rich` column.

* Neither method for computing richness aligns with `rich`.
    * Q: How is `rich` computed then?
* The rest of the analysis uses the column `rich`
```{r}
##### Kim's raw version (from NutNet_rare_spp.R). Nathan's only change is moving to the merged data.
richness_raw <- nutnetRel%>%
  filter(live==1, Family!='NULL')%>%
  group_by(year_trt, site_code, plot, trt)%>%
  summarise(richness_og =length(rel_cover))%>%
  ungroup()

#### Adapted (computed) version, counting unique taxon instead of rows, don't group by plot
richness_taxon <- nutnetRel%>%
  filter(live==1, Family!='NULL')%>%
  group_by(year_trt, site_code)%>%
  summarise(richness_adapt=length(unique(Taxon)))%>%
  ungroup()


#### Compare with the nutnet built in version. They still don't match
nutnetRel %>%
  select(year_trt, site_code, plot, trt, rich) %>%
  inner_join(richness_raw, by = c("year_trt", "site_code", "plot", "trt")) %>%
  inner_join(richness_taxon, by = c("year_trt", "site_code")) %>%
  filter(richness_og != rich | richness_adapt != rich | richness_og != richness_adapt)
  #filter(!isTRUE(all.equal(rich, richness_og, richness_adapt)))


```




### Plot 1 from `nutnet_rare_spp.R`: Biomass ~ Richness (log scale). 
* Using `rich` for richness
* Using `live_mass` for biomass
* Plotting linear and locally linear trendlines
* Including only the treatments :Control, N, NP, NPK, Fence, NPK+Fence
* We take the average richness/live mass over all Taxon
    * Equivalently, this means each point in our plot is a unique site / year / treatment / plot combination
    * Q: Is this what we want?
```{r slide4, cache = T}
# aggregate over taxon
biomass_by_trt <- nutnetPlot %>%
  filter(year_trt != 0) %>%
  group_by(site_code, year_trt, trt, plot) %>% 
  summarize(mean_rich = mean(rich),
            mean_mass = mean(live_mass))

# locally linear trendlines
(biotime_plot1_loess <- ggplot(biomass_by_trt, aes(x=log(mean_rich), y=log(mean_mass), color=trt)) + 
    #guides(color = "none") +
    geom_point(alpha = 0.01) +
    geom_smooth(method='loess', alpha=0.3, lwd=1.3, se=T) +
    #geom_smooth(pred_bef_fix, method='lm', mapping=aes(y=fit), color="black", lwd=1.5) +
    labs(x = "Log Richness",
         y = "Log Biomass",
         title = "Biomass vs Richness by Treatment",
         color = "Treatment") + 
    ylim(c(4,6.5))
)

# linear trendlines
(biotime_plot1_lm <- ggplot(biomass_by_trt, aes(x=log(mean_rich), y=log(mean_mass), color=trt)) + 
    #guides(color = "none") +
    geom_point(alpha = 0.01) +
    geom_smooth(method='lm', alpha=0.3, lwd=1.3, se=T) +
    #geom_smooth(pred_bef_fix, method='lm', mapping=aes(y=fit), color="black", lwd=1.5) +
    labs(x = "Log Richness",
         y = "Log Biomass",
         title = "Biomass vs Richness by Treatment (Linear Trendlines)") + 
    ylim(c(4,6.5))
)

```

### Plot2 from `nutnet_rare_spp.R`: Proportion of Species lost, by time

* Needs a lot of preprocessing work from Kim's script. This is confusing, and I'm pretty sure we can cut it down somehow. 
* _Note_: Need to check the computation of `nutnetdf_allspp`. I have a feeling we are `select`ing too many variables.. This will also impact the biotime plots. 
* Warning! This takes a pretty long time to run.
```{r slide5, cache = T}
nutnetpretreatdf <- nutnetRel %>%
  filter(year_trt == 0)

# Add mean and max abundance, based on year/site_code/taxon
meanmaxAb_byspecies <- nutnetpretreatdf %>%
  group_by(year, site_code, Taxon) %>%
  summarize(meanPTAbundance = mean(rel_cover, na.rm = T),
            maxPTAbundance = max(rel_cover)) %>%
  ungroup() %>%
  select(-year)

nutnetpretreatdf_live <- nutnetpretreatdf %>%
  filter(live == 1)

# Get the relative pretreatment frequency of each taxon, by year/site_code
# We first compute Total pretreatment Frequency by summing the live column (1)
# Then we get the number of plots for each site by taking max(plot) (2)
# Then we divide total frequency / number of plots (3)
tot_plots <- nutnetpretreatdf_live%>% #(2)
  select(site_code, plot)%>%
  unique()%>%
  group_by(site_code)%>%
  summarise(num_plots=max(plot))

freq <- nutnetpretreatdf_live %>%
  group_by(year, site_code, Taxon) %>%
  summarize(PTfreq = sum(live, na.rm = T)) %>% # (1)
  ungroup() %>%
  select(-year) %>%
  left_join(tot_plots, by = "site_code") %>%
  mutate(freq = PTfreq / num_plots) # (3)

# get the digroup to merge in with everything else later
di_groups <- nutnetRel %>%
  select(site_code, plot, Taxon, DIgroup) %>%
  distinct()

# 
# nutnetdf_allspp <- nutnetRel %>%
#   select(year, site_name, site_code, plot, year_trt, trt, Taxon, DIgroup, rel_cover) %>%
#   group_by(site_name, site_code) %>%
#   nest() %>% # (1)
#   mutate(spread_df = purrr::map(data, ~spread(., key = Taxon, value = rel_cover, fill = 0) %>%
#                                   gather(key = Taxon, value = rel_cover, -year:-trt))) %>% #(2)
#   unnest(spread_df) %>%
#   ungroup() %>%
#   mutate(PA = ifelse(rel_cover > 0, 1, 0)) %>% # (3)
#   arrange(site_code, plot, Taxon, year)

# NH: Maybe don't include DI? If using this one, need to add DI back by left_joining di_groups
nutnetdf_allspp <- nutnetRel %>%
  select(year, site_name, site_code, plot, year_trt, trt, Taxon, rel_cover) %>%
  group_by(site_name, site_code) %>%
  nest() %>% # (1)
  mutate(spread_df = purrr::map(data, ~spread(., key = Taxon, value = rel_cover, fill = 0) %>%
                                  gather(key = Taxon, value = rel_cover, -year:-trt))) %>% #(2)
  unnest(spread_df) %>%
  ungroup() %>%
  mutate(PA = ifelse(rel_cover > 0, 1, 0)) %>% # (3)
  arrange(site_code, plot, Taxon, year) %>%
  left_join(di_groups, by = c("site_code", "plot", "Taxon"))

# get number of years observed. will be merged in with other stuff below
nutnetdf_length <- nutnetdf_allspp%>%
  #make a column for max trt year
  group_by(site_code)%>%
  summarise(length=max(year_trt))

#get the abundance metric to merge with everything else later (NH CHANGE)
# abund_metric_df <- nutnetdf_allspp3Trt %>%
#   select(site_code, Taxon, meanPTAbundance, abund_metric) %>%
#   distinct()


nutnetPresAbs <- nutnetdf_allspp%>%
  left_join(meanmaxAb_byspecies, by=c('site_code', 'Taxon'))%>%
  left_join(freq, by=c('site_code', 'Taxon'))%>%
  mutate(abund_metric=((meanPTAbundance/100)+PTfreq)/2)%>%
  filter(year_trt>0)

nutnetPASite <- nutnetPresAbs%>%
  #get site level presence/absence by trt
  group_by(site_code, Taxon, year_trt, trt)%>%
  summarise(presence=sum(PA))%>%
  ungroup()%>%
  mutate(PA=ifelse(presence>0, 1, 0))

# Look at controls
nutnetPACtl <- nutnetPASite%>%
  filter(trt=='Control')%>%
  rename(PA_ctl=PA)%>%
  select(site_code, Taxon, year_trt, PA_ctl)

# look at treatment group and compare with controls
nutnetPASiteTrt <- nutnetPASite%>%
  filter(trt!='Control')%>%
  left_join(nutnetPACtl)%>%
  #drop species that are never present in control in a year (because those are gains in trts)
  filter(PA_ctl>0)%>%
  #merge dominance categories NH CHANGE from in-script di computation.
  # note that we're missing abund metric now, so have to add it separate
  left_join(di_groups, by = c("site_code", "Taxon"))# %>%
  #left_join(abund_metric_df, by = c("site_code", "Taxon"))

nutnetLossSite <- nutnetPASiteTrt%>%
  filter(PA==0)%>%
  group_by(site_code, year_trt, trt, DIgroup)%>%
  summarise(num_loss=length(PA))%>%
  ungroup()

# Looking at number of rows where species is present
nutnetNotLossSite <- nutnetPASiteTrt%>%
  filter(PA==1)%>%
  group_by(site_code, year_trt, trt, DIgroup)%>%
  summarise(num_notloss=length(PA))%>%
  ungroup()

# Getting the proportion of species lost in each row ?
nutnetLossorNotSite <- nutnetLossSite%>%
  full_join(nutnetNotLossSite)%>%
  mutate(num_loss=replace_na(num_loss, 0))%>%
  mutate(num_notloss=replace_na(num_notloss, 0))%>%
  mutate(total_spp=num_loss+num_notloss)%>%
  mutate(prop_loss=num_loss/total_spp)%>%
  #remove sites with no DI groups (no pretrt data)
  filter(!is.na(DIgroup))%>%
  #remove sites where trt year is not recorded
  filter(year_trt<11)


ggplot(barGraphStats(data=subset(nutnetLossorNotSite, 
                                 trt=='N'|trt=='NP'|trt=='NPK' | trt =="Fence" | trt == "NPK+Fence"), 
                     variable="prop_loss", 
                     byFactorNames=c("trt", "DIgroup", "year_trt")), 
       aes(x=year_trt, y=mean, color=as.factor(DIgroup))) +
  geom_point(stat='identity', position=position_dodge(width=0.7)) +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se), width=0.2, position=position_dodge(width=0.7)) +
  xlab('Year') + ylab('Proportion of Species Lost') +
  #scale_color_discrete(breaks=c("1", "2", "3"), labels=c("Rare", "Intermediate", "Dominant")) +
  facet_wrap(~trt) + 
  labs(color ="DI Group")


```


### Plot 3 from `nutnet_rare_spp.R`: Biomass/abudance difference over time
* Maybe include `plot` in the first group_by?
```{r slide6}
biomassResp <- nutnetRel %>%
  filter(year_trt!=0)%>%
  group_by(site_code, year_trt, trt)%>%
  summarise(live_mass_mean=mean(live_mass))%>%
  ungroup()%>%
  spread(key=trt, value=live_mass_mean)%>%
  mutate(NPK_diff=(NPK-Control)/Control, 
         N_diff=(N-Control)/Control, 
         NP_diff=(NP-Control)/Control,
         #NP_diff=(NP+Fence-Control)/Control,
         Fence_diff = (Fence - Control)/Control,
         NPKFence_diff = (`NPK+Fence` - Control)/Control)%>%
  select(site_code, year_trt, NPK_diff, N_diff, NP_diff, Fence_diff, NPKFence_diff)%>%
  na.omit()%>%
  gather(key=trt, value=diff, NPK_diff:NPKFence_diff)

(badBiomassFig <- ggplot(data=barGraphStats(data=biomassResp, variable="diff", byFactorNames=c("year_trt", "trt")), aes(x=year_trt, y=mean, color=trt)) +
    geom_point(size=3) +
    stat_smooth(method = "lm", formula = y ~ x + I(x^2), alpha = 0.2) +
    geom_errorbar(aes(ymin=mean-se, ymax=mean+se), width=0.2, alpha = 0.5) +
    xlab('Treatment Year') + ylab('Biomass Difference (%)') +
    geom_hline(yintercept=0) + 
    scale_color_discrete(name = "Treatment", labels = c("Fence", "N", "NP", "NPK", "NPK+Fence"))
  
)



```



### Plot b from Predict: Richness Difference (%) by DIGroup
* The boxplots are over all sites, and we're averaging over all years != 0
* Need to check computation of these. Based on the plot above to compute difference 
```{r slide7}
## What's are the points in the boxplot??  plot year
richness_diff_di <- nutnetRel %>%
  filter(year_trt!=0)%>%
  group_by(trt, site_code, DIgroup)%>%
  summarise(live_rich_mean=mean(rich))%>%
  ungroup()%>%
  spread(key=trt, value=live_rich_mean)%>%
  mutate(NPK_diff=(NPK-Control)/Control, 
         N_diff=(N-Control)/Control, 
         NP_diff=(NP-Control)/Control,
         #NP_diff=(NP+Fence-Control)/Control,
         Fence_diff = (Fence - Control)/Control,
         NPKFence_diff = (`NPK+Fence` - Control)/Control)%>%
  select(DIgroup, NPK = NPK_diff, N = N_diff, NP = NP_diff, Fence = Fence_diff, `NPK+Fence` = NPKFence_diff)%>%
  na.omit()%>%
  gather(key=trt, value=diff, NPK:`NPK+Fence`)


ggplot(richness_diff_di) + 
  geom_boxplot(aes(x = trt, y = diff, fill = DIgroup)) + 
  geom_hline(yintercept = 0) + 
  lims(y = c(-1,2)) + 
  labs(title = "Richness by Treatment, over all Sites",
       y = "Richness Difference (%)",
       x = "Treatment")

```


### Plot c from Predict. Abundance Diff (%) by DI Group
```{r slide8}
abund_diff_di <- nutnetRel %>%
  filter(year_trt!=0)%>%
  group_by(trt, site_code, DIgroup)%>%
  summarise(live_abund_mean=mean(DI))%>%
  ungroup()%>%
  spread(key=trt, value=live_abund_mean)%>%
  mutate(NPK_diff=(NPK-Control)/Control, 
         N_diff=(N-Control)/Control, 
         NP_diff=(NP-Control)/Control,
         #NP_diff=(NP+Fence-Control)/Control,
         Fence_diff = (Fence - Control)/Control,
         NPKFence_diff = (`NPK+Fence` - Control)/Control)%>%
  select(DIgroup, NPK = NPK_diff, N = N_diff, NP = NP_diff, Fence = Fence_diff, `NPK+Fence` = NPKFence_diff)%>%
  na.omit()%>%
  gather(key=trt, value=diff, NPK:`NPK+Fence`)

ggplot(abund_diff_di) + 
  geom_boxplot(aes(x = trt, y = diff, fill = DIgroup)) + 
  geom_hline(yintercept = 0) + 
  lims(y = c(-1,2)) + 
  labs(title = "Abundance by Treatment, over all Sites",
       y = "Abundance Difference (%)",
       x = "Treatment")



```



### Plot b from Biotime: Probability missing at the end ~ Relative Pretreatment Rank
This one and plot c from Biotime both need a LOT of work. 
* adapted from `2_biotime_sp_loss.R`
    * the comments underneath each section of code are the original biotime code. I think some of the adaptations are wrong, but you can look at the original code right underneath.
    * It looks like Kim uses some of this code in when she creates the dataframe `nutnetdf_allspp` (created above in chunk `slide5` above). I used Kim's adadptation as a starting point, but see my comments above `slide5` for some of my concerns about this.
    * I'm also not sure about groupings. I took Biotime's `STUDY_ID` identifier to be the combination of `site_code` and `plot` in our data. 
    * We probably want to think about replacing the logistic regressions with a binomial `glmer` at some point.
    * Warning: this code takes a while to run. Might be worth taking a subset of the data and working with that to save time.


```{r, cache = T}
rel_rank_year0 <- nutnetRel %>%
  filter(year_trt == 0) %>%
  select(site_code, plot, trt, Taxon, rel_abundance_year0) %>%
  group_by(site_code, trt) %>%
  mutate(rel_rank_year0 = rank(rel_abundance_year0, ties.method = "min") %>%
           scales::rescale(c(0,1))) %>% 
  ungroup()
  

# site_code, plot, year, taxon is a unique identifier in our original data (nutnetRel)
modeling_data_year0 <- nutnetdf_allspp %>% 
  select(site_code, plot, year_trt, Taxon, rel_cover) %>%
  left_join(rel_rank_year0, by = c("site_code", "plot", "Taxon")) %>%
  # figure out when a species is lost
  group_by(site_code, plot, Taxon) %>%
  filter(year_trt == max(year_trt)) %>%
  mutate(lost_at_end = ifelse(rel_cover == 0, 1, 0)) %>%
  #mutate(lost_at_end = ifelse(rel_cover[1] == 0 & lead(rel_cover) == 0, 1, 0)) %>%
  filter(#year_trt == max(year_trt),
         trt %in% c("Control", "N", "NP", "NPK", "NPK+Fence")) %>%
  ungroup()

# ggplot(aes(x = rel_rank_year0, y = lost_at_end, color = trt), data = modeling_data_year0) + 
#   geom_point(position=position_jitter(width=0.05, height=0.05),
#              alpha=0.2, color="grey") +
#     geom_smooth(method = "glm", method.args = list(family = "binomial")) + 
#   ylab("Probability of Being\n Missing at End") +
#   xlab("Relative Rank at 1st Time Step\n(Rare to Common)")




         
library(lme4)
library(merTools)

year0_model <- glmer(lost_at_end ~ rel_rank_year0  + (1|site_code/plot) + (1|Taxon),
                   data = modeling_data_year0,
                   family = "binomial")
year0_data_with_fitted_values <- modelr::add_predictions(data = modeling_data_year0, 
                                                 model = year0_model, 
                                                 type = "response")

ggplot(aes(x = rel_rank_year0, y = pred, color = trt), data = year0_data_with_fitted_values) + 
  # geom_point(aes(x = rel_rank_year0, y = lost_at_end), position=position_jitter(width=0.05, height=0.05),
  #            alpha=0.2, color="grey") +
  geom_smooth() +
  labs(
    y = "Probability of Being\n Missing at End",
    x = "Relative Rank at 1st Time Step\n(Rare to Common)",
    color = "Treatment")

ggsave("biotime_b_equiv.png")

# newdata <- crossing(site_code = modeling_data_year0$site_code %>% unique,
#                     plot = unique(modeling_data_year0$plot),
#                     rel_rank_year0 = seq(0,1,length.out = 100),
#                     Taxon = modeling_data_year0$Taxon %>% unique)
# 
# fake_pred <- predictInterval(year0_model, newdata = newdata)
# 
# fake_data <- cbind(newdata, fake_pred)
# 
# 
# (plot_year0 <- ggplot(fake_data, 
#                              aes(x = rel_rank_year0, y = lost_at_end, color = trt)) +
#     #geom_smooth(method = "glm", method.args = list(family = "binomial")) +  
#     
#   geom_line(mapping = aes(color = factor(DIgroup)),
#                           # color = factor(lag_rel_percapita_biomass_rank)),
#             size = 2) +
#   scale_color_viridis_d(guide = guide_legend(title = "Relative\nSize Rank\nAt Time T-1"),
#                         option = "D") +
#   scale_fill_viridis_d(guide = guide_legend(title = "Relative\nSize Rank\nAt Time T-1"),
#                        option = "D") +
#   # geom_ribbon(data = loss_lag_pred_fix,
#   #             mapping = aes(x = lag_rel_abund_rank,  group = lagsize_split,
#   #                           fill = factor(lag_rel_percapita_biomass_rank),
#   #                           ymin = lwr, ymax = upr), alpha = 0.3) +
#   xlab("Relative Abundance Rank At Time T-1") +
#   ylab("Probability of Loss at Time T")
# )

```



```{r biotimeB, cache = TRUE, include = F, eval = FALSE}
### This is me trying to adapt the biotime code. didn't go well.... - nh

### Get REL_RANK_T0. adapted from 1_process_biotime_sp_change.R ----------------
biotime_sum_abund <- nutnetdf_allspp %>%
  # biotime_abund %>%
  # #get values summed across SAMPLE_DESCs within a year
  # group_by(STUDY_ID, YEAR, GENUS_SPECIES, MEASURE) %>%
  # summarize(SUM_VALUE = sum(VALUE)) %>%
  # ungroup() %>%
  # 
  # #make sure we have 0s for missing species
  # group_by(STUDY_ID, MEASURE) %>%
  # nest() %>%
  # mutate(reshaped_df = purrr::map(data, ~spread(., GENUS_SPECIES, SUM_VALUE, fill=0) %>%
  #                                      gather(GENUS_SPECIES, SUM_VALUE, -YEAR))) %>%
  # unnest(reshaped_df) %>%


  # group_by(STUDY_ID, MEASURE) %>%
  # mutate(NUM_SPECIES = n_distinct(GENUS_SPECIES)) %>%
  # ungroup() %>%
  
  #now create summed abundances, relative abundances,
  #absolute rank, and relative rank
  #both including and excluding absent species
  #in each year relative to community
  group_by(site_code, plot) %>%
  mutate(ABS_RANK = rank(rel_cover, ties.method = "min"),
         REL_RANK_ALL = scales::rescale(ABS_RANK, c(0,1)),
         REL_RANK_TIMEPOINT = scales::rescale(ifelse(ABS_RANK==1,NA, ABS_RANK), c(0,1))) %>%
  # group_by(STUDY_ID, YEAR, MEASURE) %>%
  # mutate(TOTAL_VALUE = sum(SUM_VALUE),
  #        REL_VALUE_COMM = SUM_VALUE/TOTAL_VALUE,
  #        ABS_RANK = rank(REL_VALUE_COMM, ties.method = "min"), 
  #        REL_RANK_ALL = scales::rescale(ABS_RANK, c(0,1)),
  #        REL_RANK_TIMEPOINT = scales::rescale(ifelse(ABS_RANK==1,NA, ABS_RANK), c(0,1))) %>%
  ungroup() %>%
  
  # #now create total series abund for later calcultion
  # group_by(STUDY_ID, MEASURE) %>%
  # mutate( WHOLE_SERIES_TOTAL = sum(SUM_VALUE)) %>%
  # ungroup() %>%
  
  #now create summed abundances and relative abundances 
  #in each year relative to self in first appearance
  #and max and whole series relative abundance
  group_by(site_code, plot, Taxon) %>%
  arrange(year) %>%
  # group_by(STUDY_ID, MEASURE, GENUS_SPECIES) %>%
  # arrange(YEAR) %>%
  mutate(
    # LOG_SUM_VALUE = log(SUM_VALUE),
    #      REL_VALUE_TO_MAX = SUM_VALUE/max(SUM_VALUE),
    #      REL_VALUE_TO_FIRST = SUM_VALUE/SUM_VALUE[SUM_VALUE!=0][1],
    #      REL_VALUE_TO_T0 = SUM_VALUE/SUM_VALUE[1],
    #      REL_VALUE_TO_T0_T3 = SUM_VALUE/mean(SUM_VALUE[1:3]),
         REL_RANK_T0 = REL_RANK_TIMEPOINT[1]#,
         # REL_RANK_T1 = REL_RANK_TIMEPOINT[2],
         # REL_RANK_T3 = REL_RANK_TIMEPOINT[2],
         # REL_RANK_MEAN_T0_TO_T3 = mean(REL_RANK_TIMEPOINT[1:3]),
         # Z_TRANS_VALUE = (SUM_VALUE - mean(SUM_VALUE))/sd(SUM_VALUE),
         # Z_TRANS_LOG_VALUE = (LOG_SUM_VALUE - mean(LOG_SUM_VALUE))/sd(LOG_SUM_VALUE),
         # CV_LOG_VALUE = sd(LOG_SUM_VALUE)/mean(LOG_SUM_VALUE),
         # REL_VALUE_COMM_T0 = REL_VALUE_COMM[1],
         # REL_VALUE_COMM_T0_T3 = mean(REL_VALUE_COMM[1:3]),
         # N_YEARS = length(YEAR),
         # WHOLE_SERIES_REL_VALUE = sum(SUM_VALUE)/WHOLE_SERIES_TOTAL
         ) %>%
  arrange(desc(year)) %>%
  #arrange(desc(YEAR)) %>%
  #mutate(MISSING_FINAL_3_YRS = sum(SUM_VALUE[1:3])>0) %>%
  ungroup()


### Get  `lost_at_end` (also from `1_process_biotime_sp_change.R) -------------------------
biotime_loss <- biotime_sum_abund %>%
  group_by(site_code, plot, Taxon) %>%
  #group_by(STUDY_ID, GENUS_SPECIES, MEASURE) %>%

  #cut out first year
  arrange(year) %>%
  #arrange(YEAR) %>%
  
  slice(2:n()) %>%
  
  #get loss information
  summarize(n_year = 1 + n_distinct(year),
            lost_at_end = as.numeric(rel_cover[n()] == 0)) %>%
  # summarize(n_year = 1+n_distinct(YEAR),
  #           n_zeros = sum(SUM_VALUE==0),
  #           lost_at_end = as.numeric(SUM_VALUE[n()]==0)) %>%
  ungroup() #%>%
  # mutate(frac_missing_after_t0 = n_zeros/n_year)


#### Merge different derived datasets ####
biotime_loss_summary <- biotime_sum_abund %>%
  #get year 0 only
  group_by(site_code, plot, Taxon) %>%
  arrange(year) %>%
  # group_by(STUDY_ID, GENUS_SPECIES, MEASURE) %>%
  # arrange(YEAR) %>%
  slice(1L) %>%
  ungroup() %>%
  
  #join with loss data
  left_join(biotime_loss) %>%
  
  #get rid of rel abundance of 0 in t0
  filter(rel_cover != 0) %>%
  # filter(SUM_VALUE != 0) %>%
  
  #are you always present in the timeseries?
  # mutate(absent_at_some_point = ifelse(frac_missing_after_t0 !=0, 1, 0)) %>%

  #don't need year, as it's first year only
  dplyr::select(-year)
  # dplyr::select(-YEAR)


###### PLOT
(missing_at_end <- ggplot(biotime_loss_summary,
       # aes(x=REL_RANK_T0, y=lost_at_end, group=as.character(STUDY_ID))) +
       aes(x=REL_RANK_T0, y=lost_at_end, color = trt)) +
  geom_point(position=position_jitter(width=0.05, height=0.05),
             alpha=0.2, color="grey") +
    geom_smooth(method = "glm", method.args = list(family = "binomial")) + 
    # geom_smooth(data = biotime_loss_summary, 
    #             method = "glm", method.args = list(family = "binomial"), 
    #             formula = lost_at_end ~ REL_RANK_T0) + 
    #geom_smooth() + 
  # geom_line(data = pred_final_loss_ranef,
  #           mapping=aes(y=fit, group=as.character(STUDY_ID)),
  #             lwd=0.4, alpha=0.4, color="lightgrey") +
  # geom_line(data = pred_final_loss_fixed,
  #             mapping=aes(y=fit),
  #             color="black", lwd=1.3) +
  ylab("Probability of Being\n Missing at End") +
  xlab("Relative Rank at 1st Time Step\n(Rare to Common)"))





```


### Plot c from biotime.
* adapted from `5_biotime_abund_biomass_loss.R`
  * The biotime code looks like it actually has time t = 0 on the x axis... not a shifting t-1
* see concerns from plot b in the chunk above.
   * the `group_by`'s are my biggest concern.
* The problem is that the `rel_cover` == 0 rows are artifically created in `nutnetdf_allspp` (with the spread/gather shenanigans), and every new row also corresponds to a new treatment year. This means that we're inducing a TON of zeroes, so that the rankings (which treat all the 0's as a tie for 0), create this huge gap in the ranking between 0 and the next value. To "fix" this issue, I excluded the 0's, ranked the remaining observations, and threw the 0's back in there.

```{r, cache = T}
### Compute the relative cover rankings within each site code and treatment
#     To stop the ton of induced zeroes from impacting the rankings, we 
#         (1) Turn the zeroes into NAs
#         (2) Use the "na.last" argument in `rank` to exclude NAs from ranking
#         (3) Rank the observations and change the ranking scale to be in (0,1)
#         (4) Change the NA ranks back to zeroes.
#         (5) Shift the ranks back so that they refer to the year before

rel_rank_by_year <- nutnetdf_allspp %>%
  select(site_code, plot, year_trt, Taxon, rel_cover, trt) %>%
  # # we want to make the ranking based on mean realtive cover for taxon in a given plot and year.
  # group_by(site_code, plot, Taxon, year_trt) %>%
  arrange(site_code, plot, Taxon, year_trt) %>%
  # mutate(rel_abundance = mean(rel_cover)) %>%
  # ungroup() %>%
  # we want to rank the taxon among all the plots in a given site for a given treatment
  group_by(site_code, trt) %>%
  # mutate(rel_rank = rank(rel_abundance, ties.method = "min")) %>%
  # mutate(rel_rank = ifelse(rel_cover == 0, 0, rel_rank)) %>%
  # mutate(rel_rank = rel_rank)
  mutate(rel_cover_explicit_na = ifelse(rel_cover == 0, NA, rel_cover), #(1)
         rel_rank_scaled = rank(rel_cover_explicit_na, ties.method = "min", na.last = "keep") %>% #(2)
           scales::rescale(c(0,1)),  #(3)
         rel_rank_implicit_na = ifelse(is.na(rel_rank_scaled), 0, rel_rank_scaled), #(4)
         # only works because we sort by year
         rel_rank_lag = lag(rel_rank_implicit_na)) %>%  #(5)
  select(-rel_cover) %>%
  ungroup()


treatments <- nutnetRel %>%
  select(trt, site_code, plot, Taxon)

# site_code, plot, year, taxon is a unique identifier in our data
modeling_data <- nutnetdf_allspp %>% 
  left_join(rel_rank_by_year, by = c("site_code", "plot", "Taxon", "year_trt")) %>%
  select(site_code, plot, year_trt, Taxon, rel_cover, rel_rank_lag) %>%
  # the join creates NAs in lag_rel_rank at all the new "year_trts" from the new rows
  left_join(treatments, by = c("site_code", "plot", "Taxon")) %>%
  # figure out when a species is lost
  group_by(site_code, plot, Taxon, year_trt) %>%
  #mutate(lost = ifelse(rel_cover ==0 & rel_rank_lag != 0, 1, 0)) %>%
  mutate(lost = ifelse(rel_cover == 0, 1, 0)) %>%
  ungroup() %>%
  filter(trt %in% c("Control", "N", "NP", "NPK", "NPK+Fence")) 

# # plot using a single variable glm.
# ggplot(aes(x = rel_rank_lag, y = lost, color = trt), data = modeling_data) + 
#   # geom_point(position=position_jitter(width=0.05, height=0.05),
#   #            alpha=0.2, color="grey") +
#     geom_smooth(method = "glm", method.args = list(family = "binomial")) + 
#   labs(x = "Relative Abundance Rank at Time T-1",
#        y = "Probability of Loss at Time T",
#        color = "Treatment")

# try a mixed effects model
multiyear_model <- glmer(lost ~ rel_rank_lag  + (1|site_code/plot) + (1|Taxon),
                   data = modeling_data,
                   family = "binomial")

summary(multiyear_model)
car::Anova(multiyear_model)
#piecewiseSEM::rsquared(multiyear_model)


# add a column in the dataframe for predictions
multiyear_data_with_fitted_values <- modelr::add_predictions(data = modeling_data, 
                                                 model = multiyear_model, 
                                                 type = "response")

# plot the mixed effects model.
ggplot(aes(x = rel_rank_lag, y = pred, color = trt), data = multiyear_data_with_fitted_values) + 
  geom_smooth() +
  labs(x = "Relative Abundance Rank at Time T-1",
       y = "Probability of Loss at Time T",
       color = "Treatment")

ggsave("biotime_c_equiv.png")

```

```{r biotimeC, eval = FALSE, include = FALSE}
##### this is me trying to adapt the biotime code line by line.. .didn't go well.


# biotime_duo_reshape adds a rank/ relative rank for every site_code, plot, Taxon,
# and computes "lost" by if it has 0 cover 2 years in a row.

# biotime_duo <- biotime_sum_abund %>%
#   group_by(site_code, plot) %>%
  # group_by(STUDY_ID) %>%
  # mutate(num_measures = length(unique(MEASURE))) %>%
  # filter(num_measures==2)  %>%
  # filter(length(unique(YEAR))>3)

#biotime_duo_reshape <- biotime_duo %>%
biotime_duo_reshape <- biotime_sum_abund %>%
  dplyr::select(site_code, plot, year, Taxon, rel_cover) %>%
  dplyr::left_join(di_groups, by = c("site_code", "plot", "Taxon")) %>%
  group_by(site_code, plot, year) %>%
  # dplyr::select(STUDY_ID, YEAR, GENUS_SPECIES, MEASURE, SUM_VALUE) %>%
  # spread(MEASURE, SUM_VALUE) %>%
  # group_by(STUDY_ID, YEAR) %>%
  
  #make ranks, etc
  mutate(abund_rank = rank(rel_cover,  ties.method = "min")
  # mutate(abund_rank = rank(Abundance,  ties.method = "min"),
         # biomass_rank = rank(Biomass, ties.method = "min"),
         # percapita_biomass_rank = rank(Biomass/Abundance, ties.method = "min")
  ) %>%
  
  #deal with zeroes - make them rank 0 and recenter ranks
  mutate(abund_rank = ifelse(rel_cover == 0, 0, abund_rank)) %>%
  # mutate(abund_rank = ifelse(Abundance==0,0,abund_rank),
  #        biomass_rank = ifelse(Abundance==0,0,biomass_rank),
  #        percapita_biomass_rank = ifelse(Abundance==0,0,percapita_biomass_rank)
  # ) %>%
  #rescaling
  mutate(abund_rank = abund_rank - min(abund_rank[abund_rank!=0]) + 1) %>%#,
         # biomass_rank = biomass_rank - min(biomass_rank[biomass_rank!=0]) + 1,
         # percapita_biomass_rank = percapita_biomass_rank - min(percapita_biomass_rank[percapita_biomass_rank!=0]) + 1) %>%
  mutate(abund_rank = ifelse(abund_rank<0,0,abund_rank)) %>%#,
         # biomass_rank = ifelse(biomass_rank<0,0,biomass_rank),
         # percapita_biomass_rank = ifelse(percapita_biomass_rank<0,0,percapita_biomass_rank)) %>%
  
  #make relative ranks, etc
  mutate(rel_abund = rel_cover / max(rel_cover, na.rm = TRUE),
  # mutate(rel_abund = Abundance / max(Abundance, na.rm=TRUE),
  #        rel_biomass = Biomass / max(Biomass, na.rm=TRUE),
         rel_abund_rank = abund_rank / max(abund_rank, na.rm=TRUE)
  #        rel_biomass_rank = biomass_rank / max(biomass_rank, na.rm=TRUE),
  #        rel_percapita_biomass_rank = percapita_biomass_rank / max(percapita_biomass_rank, na.rm=TRUE),
  ) %>%
  
  # put together losses and initial relative ranks 
  group_by(site_code, plot, Taxon) %>%
  arrange(year) %>%
  # group_by(STUDY_ID, GENUS_SPECIES) %>%
  # arrange(YEAR) %>%
  mutate(rel_abund_rank = rel_abund_rank[1],
         # rel_biomass_rank = rel_biomass_rank[1],
         # rel_percapita_biomass_rank = rel_percapita_biomass_rank[1],
         # rel_abund_rank_t1_t3 = mean(rel_abund_rank[1:3]),
         # rel_biomass_rank_t1_t3 = mean(rel_biomass_rank[1:3]),
         # rel_percapita_biomass_rank_t1_t3 = mean(rel_percapita_biomass_rank[1:3]),
         lag_rel_abund_rank = lag(rel_abund_rank),
         # lag_rel_biomass_rank = lag(rel_biomass_rank),
         # lag_rel_percapita_biomass_rank = lag(rel_percapita_biomass_rank),
         
         lost = rel_cover == 0 & lag_rel_abund_rank != 0) %>%
         # lost = Abundance==0 & lag_rel_abund_rank !=0,
         # present_t1_t3 = sum(Abundance[1:3]!=0) == 3) %>%
  ungroup()


# for modeling, it's ignoring all the NAs anyways, so might as well drop them now
# but this gets rid of 6/7 of our data, so we should figure out a way around this.
modeling_data <- biotime_duo_reshape %>%
  drop_na(lost, trt, lag_rel_abund_rank, Taxon, site_code, plot)

# Q: is it worth it to add all these random intercept terms?
# A1: one approach is to see how different distributions are within each group.
modeling_data  %>% 
  mutate(lost = ifelse(lost == TRUE, 1, 0)) %>%
  ggplot() + 
  geom_smooth(aes(x = lag_rel_abund_rank, y = lost), 
              method = "glm", method.args = list(family = "binomial")) + 
  facet_wrap(~  plot)



# A2: another approach is to compare it to a fixed effects model
loss_fixed_lag <- glm(lost ~ lag_rel_abund_rank + trt + Taxon + site_code, 
                      data = modeling_data)


# fit logistic mixed effects model on p(lost given past relative abundance rank)
# include random effect for plot? ie assume that obs in same plot might look similar
loss_mod_lag <- glmer(lost ~ lag_rel_abund_rank + DIgroup + (1|site_code/plot/Taxon), 
                      data = biotime_duo_reshape, family = "binomial")
# loss_mod_lag <- glmer(lost ~ lag_rel_abund_rank*lag_rel_percapita_biomass_rank +
#                     (1|GENUS_SPECIES) +
#                     (1 |STUDY_ID),
#                   data = biotime_duo_reshape,
#                   family = "binomial")

# To get a sense of the entire distribution, make predictions on a dummy sample
n <- 100
f <- factor(levels(cut_interval(seq(0,1,.01),4)), 
            levels = levels(cut_interval(seq(0,1,.01),4)))

newdata <- crossing(lag_rel_abund_rank = seq(0,1,length.out=n),
                     tibble(lag_rel_percapita_biomass_rank = c(0.125, 0.375, 0.625, 0.875),
                            lagsize_split = f),
                    modeling_data %>%
                      group_by(site_code, Taxon, trt, plot) %>%
                      slice(1L) %>%
                      ungroup() %>%
                      dplyr::select(site_code, Taxon, trt, plot))

fixed_pred <- modelr::add_predictions(newdata, loss_fixed_lag, type = "response")
ggplot(fixed_pred) +
  geom_smooth(aes(x = lag_rel_abund_rank, y = pred, color = DIgroup), method = "loess")

loss_lag_pred_fix <- predictInterval(loss_mod_lag,
                                 newdata=newdata,
                                 which="fixed", type="probability",
                                 include.resid.var = FALSE,
                                 seed = 1,
                                 .parallel = T)

loss_lag_pred_fix <- cbind(newdata, loss_lag_pred_fix)




# newdata <- crossing(lag_rel_abund_rank = seq(0,1,length.out=n),
#                      tibble(lag_rel_percapita_biomass_rank = c(0.125, 0.375, 0.625, 0.875),
#                             lagsize_split = f),
#                     biotime_duo %>%
#                       group_by(STUDY_ID, GENUS_SPECIES) %>%
#                       slice(1L) %>%
#                       ungroup() %>%
#                       dplyr::select(STUDY_ID, GENUS_SPECIES) %>% slice(1L))
# 
# loss_lag_pred_fix <- predictInterval(loss_mod_lag,
#                                  newdata=newdata,
#                                  which="fixed", type="probability",
#                                  include.resid.var = FALSE)
# 
# loss_lag_pred_fix <- cbind(newdata, loss_lag_pred_fix)




(plot_fit_loss_mod <- ggplot(biotime_duo_reshape, 
                             aes(x = lag_rel_abund_rank, y = pred, color = DIgroup)) +
    #geom_smooth(method = "glm", method.args = list(family = "binomial")) +  
    
  geom_line(data = loss_lag_pred_fix,
            mapping = aes(x = lag_rel_abund_rank, y = fit, group = lagsize_split,
                          color = factor(DIgroup)),
                          # color = factor(lag_rel_percapita_biomass_rank)),
            size = 2) +
  scale_color_viridis_d(guide = guide_legend(title = "Relative\nSize Rank\nAt Time T-1"),
                        option = "D") +
  scale_fill_viridis_d(guide = guide_legend(title = "Relative\nSize Rank\nAt Time T-1"),
                       option = "D") +
  # geom_ribbon(data = loss_lag_pred_fix,
  #             mapping = aes(x = lag_rel_abund_rank,  group = lagsize_split,
  #                           fill = factor(lag_rel_percapita_biomass_rank),
  #                           ymin = lwr, ymax = upr), alpha = 0.3) +
  xlab("Relative Abundance Rank At Time T-1") +
  ylab("Probability of Loss at Time T")
)

```







